{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal \n",
    "\n",
    "En este cuaderno programaremos nuestra primera regresión lineal sobre una base de datos de Facebook. A partir de las distintas variables vamos a intentar predecir el número de likes de una publicación. Emplearemos los siguientes módulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook omitiremos las advertencias para evitar sobrecargar la pantalla con información innecesaria. Si deseas ver las advertencias simplemente no ejecutes la siguiente celda. __Las advertencias no son lo mismo que los errores.__ En ocasiones puede aparecernos una advertencia pero si estamos seguros de lo que estamos haciendo no es un problema. Un error por el contrario corta el flujo de ejecución y debe solventarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Comenzamos cargando nuestros datos a partir del archivo csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_facebook = pd.read_csv('./data/dataset_Facebook.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los datos se han cargado de manera correcta y comprobamos la cantidad de datos de la que disponemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_facebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_facebook.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos consta de 500 observaciones y 19 variables. Observemos las variables con algo más de atención:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_facebook.columns # columns nos devuelve el nombre de las columnas de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diccionario de datos\n",
    "\n",
    "A continuación se presenta el diccionario de datos con el significado de cada variable:\n",
    "\n",
    "* **Page total likes**. El número de likes que acumula la página.\n",
    "* **Type**. El tipo de publicación si es una foto, un vídeo, un status.\n",
    "* **Category**. La categoría en la que se enmarca que viene codificada por un entero.\n",
    "* **Post Month**. El mes en el que se realiza la publicación.\n",
    "* **Post Weekeday**. El día de la semana en el que se realiza la publicación.\n",
    "* **Post Hour**. La hora en la que se realiza la publicación.\n",
    "* **Paid**. Si el post está pagado o no.\n",
    "* **Lifetime Post Total Reach**. A cuánta gente alcanza el post en total.\n",
    "* **Lifetime Post Total Impressions**. Cuántas impresiones recibe el post en total.\n",
    "* **Lifetime Post Consumers**. Número de personas a las que aparece el post.\n",
    "* **Lifetime Post Consumptions**. Número de veces que aparece el post.\n",
    "* **Lifetime Post Impressions by people who have liked your Page**. Impresiones por personas que te siguen.\n",
    "* **Lifetime Post reach by people who like your Page**. Alcance a personas que te siguen.\n",
    "* **Lifetime People who have liked your Page and engaged with your post**. Número de personas que comienzan a seguirte debido a ese post.\n",
    "* **Comment**. Número de comentarios en el post.\n",
    "* **Like**. Número de me gustas en el post.\n",
    "* **Share**. Número de veces que se comparta el post.\n",
    "* **Total Interactions**. Número total de interacciones del post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si observamos las variables del 7 al 15 son variables __a posteriori__, es decir, cuando subimos un nuevo post no sabemos cuánto consumo va a tener o cuál va a ser el número total de impresiones por lo que descartamos dichas variables. ¿Qué sentido tendría para predecir los likes de una foto usar datos que solo se sabrán cuando hayamos subido la foto?\n",
    "\n",
    "Descartamos dichas variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_facebook.drop(data_facebook.columns[7:15], axis=1,inplace=True)  #drop nos permite eliminar columnas con axis=1 y filas con axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_facebook.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente tampoco conocemos el número de veces que se comparte, los comentarios y el número total de las interacciones por lo que las eliminamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables = data_facebook[['Page total likes', 'Type', 'Category', 'Post Month', 'Post Weekday', 'Post Hour', 'Paid', 'like']] #seleccionamos las variables que nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es nuestro conjunto final de variables. Procedemos al análisis exploratorio.\n",
    "\n",
    "## Análisis Exploratorio\n",
    "\n",
    "### Variables cuantitativas\n",
    "\n",
    "Las variables continuas son `Page total likes` y `like`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['Page total likes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reutilizamos la función estudiada en el notebook de análisis exploratorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quantitative_variables(dataframe, list_quantitative_columns):\n",
    "    for variable in list_quantitative_columns:\n",
    "        plt.pyplot.figure()\n",
    "        dataframe[variable].plot(kind = 'hist', title=variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_variables = ['Page total likes', 'like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantitative_variables(final_variables, quantitative_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que en cuanto a la distribución de likes casi todos se concentran entre los 1000 y los 2000 aunque existen unos cuantos también en 5000.\n",
    "\n",
    "A primera vista podemos pensar que las publicaciones son de influencers y personas famosas viendo el número total de likes acumulados. Sin embargo al observar la distrbución de likes los números indican que son publicaciones que no tienen tantos likes. \n",
    "\n",
    "Numéricamente podemos observar que los datos están bastante bien distribuidos pues la media y la mediana se encuentran muy próximos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['Page total likes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['like'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta observación nos permite ver que el número medio de likes es 177 lo cual descarta nuestra idea inicial de que eran posts de famosos e influencers.\n",
    "\n",
    "A continuación vemos las variables categóricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables categóricas\n",
    "\n",
    "El resto de variables son categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_variables(dataframe, list_categorical_columns):\n",
    "    for variable in list_categorical_columns:\n",
    "        plt.pyplot.figure()\n",
    "        dataframe[variable].value_counts().sort_index().plot(kind='bar', title=variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Type', 'Category', 'Post Month', 'Post Weekday', 'Post Hour', 'Paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_variables(final_variables, categorical_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando variable por variable observamos que:\n",
    "\n",
    "* Con diferencia el tipo de contenido más habitual son fotografías siendo los vídeos muy poco frecuentes.\n",
    "* Que las tres posibles categorías se encuentran más o menos equilibradas.\n",
    "* Que no se observa una tendencia clara en las publicaciones por mes.\n",
    "* Que los posts se encuentran más o menos distribuidos a lo largo de la semana con una pequeña superioridad del fin de semana.\n",
    "* Que las principales horas para estos posts se han encontrado en la mañana y en la madrugada.\n",
    "* Los posts no pagados son mucho más frecuentes que los no pagados. Estas clases no se encuentran equilibradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestión de valores no definidos\n",
    "\n",
    "Observamos si existen valores no definidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno o dos registros tienen una variable no definida. Podemos eliminar estas dos filas sin perder mucha información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingeniería de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ocasiones resulta interesante a fin de dar más claridad a los datos cambiar el nombre de algunas categorías o categorizarlas de forma distintas. Además para trabajar con un modelo de regresión lineal es más útil generar variables dummy tal y cómo vimos en las secciones teóricas. En esta sección nos ocuparemos de dichas transformaciones:\n",
    "\n",
    "### Tipo de publicación\n",
    "\n",
    "Dividimos esta variable en tres dummies (usando cuatro habría problemas de multicolinearidad) para sus cuatro posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['Video'] = pd.get_dummies(final_variables['Type'])['Video']\n",
    "final_variables['Status'] = pd.get_dummies(final_variables['Type'])['Status']\n",
    "final_variables['Photo'] = pd.get_dummies(final_variables['Type'])['Photo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de enlace quedan codificados como un cero en las tres nuevas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Like\n",
    "\n",
    "Como los likes son enteros los almacenamos en una variable entera en lugar de un float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['like'] = final_variables['like'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoría\n",
    "\n",
    "Aplicamos un razonamiento análogo al de tipo de publicación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['Cat_1'] = pd.get_dummies(final_variables['Category'])[1]\n",
    "final_variables['Cat_2'] = pd.get_dummies(final_variables['Category'])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mes del post\n",
    "\n",
    "Generamos las variables dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_variables = pd.get_dummies(final_variables['Post Month'],prefix='Mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos el representante de diciembre de nuevo para evitar colinearidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_variables.drop(month_variables.columns[-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjuntamos las nuevas variables al dataset inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables = pd.concat([final_variables,month_variables],axis=1) # concat concatena los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Día de semana del post\n",
    "\n",
    "En este caso vamos a cambiar los días por sus nombres para poder observarlos mejor. \n",
    "\n",
    "__Nota.__ Esto sería posible hacerlo también con la variable de los meses, puedes probar a hacerlo tu mismo con un esquema análogo a este.\n",
    "\n",
    "Definimos una función que sustituye el número por el nombre del día:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_day(x):\n",
    "    if x == 1:\n",
    "        return 'Domingo'\n",
    "    elif x== 2:\n",
    "        return 'Lunes'\n",
    "    elif x == 3:\n",
    "        return 'Martes'\n",
    "    elif x == 4:\n",
    "        return 'Miércoles'\n",
    "    elif x == 5:\n",
    "        return 'Jueves'\n",
    "    elif x ==6:\n",
    "        return 'Viernes'\n",
    "    elif x == 7:\n",
    "        return \"Sábado\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamo la función a la columna y observamos el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['Post Weekday'] = final_variables['Post Weekday'].apply(lambda x: replace_day(x))  # el método apply aplica la función a cada elemento de la columna Post Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las dummies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_variables = pd.get_dummies(final_variables['Post Weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos la del viernes para evitar colinearidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_variables.drop(weekday_variables.columns[-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las añadimos a las ya existentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables = pd.concat([final_variables,weekday_variables],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hora del post\n",
    "\n",
    "De nuevo el mismo proceso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_variables = pd.get_dummies(final_variables['Post Hour'], prefix='Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las añadimos a nuestras variables. Como siempre eliminamos la última para evitar multicolinearidad y las añadimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_variables.drop(hour_variables.columns[-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables = pd.concat([final_variables,hour_variables],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagado\n",
    "\n",
    "Convertimos esta variable a string con dos posibles valores: `Sí` cuando esté pagada y `No` cuando no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pay(x):\n",
    "    if int(x)==1:\n",
    "        return 'Sí'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos a la columna la función de sustitución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['Paid'] = final_variables['Paid'].apply(lambda x: replace_pay(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos una sola dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables['Is_Paid'] = pd.get_dummies(final_variables['Paid'])['Sí']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente eliminamos las variables categóricas iniciales pues ya tenemos la información de las mismas almacenadas en las variables dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.drop(['Type', 'Category', 'Post Month', 'Post Weekday', 'Post Hour', 'Paid'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas son nuestras variables finales tras la ingeniería de variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí el proceso inicial de limpieza de datos e ingeniería de variables. Procedemos a continuación a guardar una copia de los datos en un archivo csv. Esto es muy práctico sobre todo cuando se trabaja con grandes cantidades de datos y el proceso de limpieza lleva minutos o incluso horas. También si planeamos reutilizar el conjunto de datos en un futuro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.to_csv('./data/cleaned_facebook.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del modelo\n",
    "\n",
    "### Instalando scikit-learn\n",
    "\n",
    "El módulo más popular para la construcción de modelos de Machine Learning en Python es sin duda `scikit.learn` que implemente distintos modelos tanto de clasificación como de regresión así como funciones ya implementadas y optimizadas para realizar tareas como la separación de los datos en datos de entrenamiento y de evaluación o el cómputo de distintas métricas. Es necesario en primer lugar instalar el módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook emplearemos las siguientes herramientas contenidas en el módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supresión de outliers\n",
    "\n",
    "Por últimos vamos a eliminar los datos atípicos en la variable a predecir. Para ello simplemente suprimimos aquellas filas en las que los valores de la variable `like` están por encima del percentil 95. Para ello calculamos dicho percentil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierCut = np.percentile(final_variables['like'],95) #calculamos el percentil 95\n",
    "outlierCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prescindimos de dichas filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables = final_variables[final_variables['like']<outlierCut] #nos quedamos con los valores que tienen menos del percentil 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de los datos\n",
    "\n",
    "Como hemos visto en las secciones teóricas para evaluar un modelo de manera correcta es necesario mantener una parte de los datos oculta al modelo durante el entrenamiento. A continuación se procede a la separación en variables predictoras y variable objetivo y la separación en dos conjuntos uno de entrenamiento y otro de validación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos las variables predictoras en un dataframe X y la variable objetivo en un dataframe y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_variables.drop(['like'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_variables[['like']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `train_test_split` nos permite dividir nuestro conjunto de variables predictoras y variable objetivo en entrenamiento y validación generando X_train con los registros de las variables predictores destinados al entrenamieno, y_train con los registros de la variable objetivo para entrenamiento, X_test con los de predictoras destinados a validación y y_test con los de objetivo destinados a validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalado de variables continuas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos la variable numérica para lograr un modelo con coeficientes mejor ajustados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nota.__ Por tratarse de una única variable (normalmente  el escalado se hace de varias) es necesario cambiar algunos atributos para el buen funcionamiento, por eso compartimos la variable en un array y le cambios la forma con el método `reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train = StandardScaler() #instanciamos el escalador\n",
    "scaler_train.fit(asarray(x_train['Page total likes']).reshape(-1, 1))\n",
    "x_train['Page total likes'] = scaler_train.transform(asarray(x_train['Page total likes']).reshape(-1,1)) #escalamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_test = StandardScaler()\n",
    "scaler_test.fit(asarray(x_test['Page total likes']).reshape(-1, 1))\n",
    "x_test['Page total likes'] = scaler_test.transform(asarray(x_test['Page total likes']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que se ha escalado correctamente. Como se centra en torno a 0 aparecen valores negativos, es totalmente normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras todo el proceso de limpieza de datos ha llegado el momento de construir nuestro primer modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal simple\n",
    "\n",
    "Comenzamos construytendo el modelo más simple en el que intentamos predecir el número de likes a partir de una sola variable, por ejemplo, `Page total likes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_total_likes = x_train['Page total likes']\n",
    "x_test_total_likes = x_test['Page total likes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empleamos la clase `linear_model` de Scikit-Learn para generar nuestro modelo que almacenamos en `simple_reg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_reg = linear_model.LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo dándole los datos sobre el total de likes en la variable `x_train_total_likes` y los datos de likes (la etiqueta) en la variable `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_reg.fit(asarray(x_train_total_likes).reshape(-1,1) ,y_train) #el método fit calcula los parámetros a partir de los datos provistos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo ya está entrenado, es decir, ya hemos calculado los coeficientes del modelo. En este caso por ser una regresión simple tenemos el término constante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_reg.intercept_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y la pendiente de la recta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_reg.coef_[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que la ecuación final de nuestra regresión sería:\n",
    "<i><center>y = 133198.5839290403 * x + 1015423.7612912263</center></i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de este modelo ya entrenado podemos realizar una predicción sobre el conjunto de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_simple = simple_reg.predict(asarray(x_test_total_likes).reshape(-1,1)) #el método predict genera predicciones a partir de un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos como primer método de validación y por tratarse de una regresión lineal simple graficar las dos variables (variable predictora y variable objetivo) al igual que la recta de la regresión lineal para ver cómo funciona en validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.scatter(x_test_total_likes, y_test,  color='orange', alpha = 0.8)\n",
    "plt.pyplot.plot(x_test_total_likes, y_pred_simple, color='black', linewidth=1)\n",
    "plt.pyplot.xlabel('Page Total Likes')\n",
    "plt.pyplot.ylabel('Likes')\n",
    "\n",
    "\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nota.__ No te asustes por los valores de `Page Total Likes` recuerda que los habíamos escalado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último es posible calcular el R2 asociado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_simple_train = simple_reg.predict(asarray(x_train_total_likes).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore = r2_score(y_pred=y_pred_simple_train,y_true=y_train) #r2_Score nos permite calcular el R2 asociado\n",
    "trainScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScore_simple = r2_score(y_pred=y_pred_simple,y_true=y_test)\n",
    "testScore_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal múltiple. Modelo básico\n",
    "\n",
    "Empleamos la clase `linear_model` de Scikit-Learn para generar nuestro modelo que almacenamos en basic_reg. En este caso ya trabajamos con todas las variables predictoras disponibles en lugar de solo con el Page Total Likes como ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_reg = linear_model.LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez instanciado el modelo, procedemos a entrenarlo mediante el método `fit()` que recibe como parámetros los datos de entrenamiento y la etiqueta de dichos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas dos simples líneas ya hemos construido nuestro modelo de regresión lineal múltiple, mediante el atributo `coef_` podemos observar cuáles son sus coeficientes estimados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_reg.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejor comprensión podemos hacer una tabla para ver con que variable va asociado cada coeficiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = X.columns.tolist()\n",
    "variable_coef= {'Variable' : variables, 'Coeficiente': basic_reg.coef_[0]}\n",
    "variable_coef_tabla = pd.DataFrame(variable_coef)\n",
    "variable_coef_tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí hemos construido nuestro segundo modelo. A continuación vamos a evaluar su calidad.\n",
    "\n",
    "## Evaluación del modelo\n",
    "\n",
    "Para evaluar este modelo recurrimos al conjunto de datos que dejamos apartado para validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_basic_train = basic_reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_basic = basic_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore_basic = r2_score(y_pred=y_pred_basic_train,y_true=y_train)\n",
    "trainScore_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScore_basic = r2_score(y_pred=y_pred_basic,y_true=y_test)\n",
    "testScore_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización\n",
    "\n",
    "Como vimos en las secciones teóricas la regularización nos permite hacer nuestro modelo más preciso y robusto a pequeñas variaciones en los datos. En este caso examinaremos tres posibilidades: _regresión ridge, regresión lasso_ y _elastic net_:\n",
    "\n",
    "### Regresión Ridge\n",
    "\n",
    "El propio `scikit-learn` nos aporta el método para la regresión ridge implementado. Lo implementamos con un abanico de posibles alphas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrimos al mismo método para entrenar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante validación cruzada el modelo ha obtenido el alpha óptimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo podemos emplear el conjunto de validación para evaluarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge_train = ridge_reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore_ridge = r2_score(y_pred=y_pred_ridge_train,y_true=y_train)\n",
    "trainScore_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge_test = ridge_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScore_ridge = r2_score(y_pred=y_pred_ridge_test,y_true=y_test)\n",
    "testScore_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión calculamos de manera análoga una regresión usando regularización Lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = linear_model.LassoCV(alphas=np.linspace(0,1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El alpha ideal ha sido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre evaluamos la calidad en validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lasso_train = lasso_reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore_lasso = r2_score(y_pred=y_pred_lasso_train,y_true=y_train)\n",
    "trainScore_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lasso_test = lasso_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScore_lasso = r2_score(y_pred=y_pred_lasso_test,y_true=y_test)\n",
    "testScore_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último probaremos con elastic net. Empleamos validación cruzada para elegir el parámetros alpha más adecuado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_reg = linear_model.ElasticNetCV(cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El alpha más adecuado ha sido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo calculamos R2 sobre validación para evaluar la calidad del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_elastic_train = elastic_net_reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore_elastic = r2_score(y_pred=y_pred_elastic_train,y_true=y_train)\n",
    "trainScore_elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_elastic_test = elastic_net_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScore_elastic = r2_score(y_pred=y_pred_elastic_test,y_true=y_test)\n",
    "testScore_elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar y conclusiones\n",
    "\n",
    "Construimos una pequeña tabla en la que almacenamos los resultados obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Simple': testScore_simple, 'Múltiple': testScore_basic, 'Cresta':testScore_ridge, 'Lasso': testScore_lasso, 'Elastic net': testScore_elastic  }\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el mejor modelo es la regresión lasso pues es aquel que tiene el mayor R2 asociado. Observamos que hay valores negativos, es porque trabajamos con R2 y no con R2 ajustado. Calculamos finalmente para evaluar su calidad el error medio cuadrático de la regresión lasso en el conjunto de validación. Ya hemos calculado previamente la predicción así que la podemos reutilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred_lasso_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De media se equivoca en unos 93 likes, si recordamos nuestros datos de likes oscilan entre 0 y 485 por lo que fallar 93 de media es bastante elevado. Es decir, tenemos un modelo base pero será necesario en secciones posteriores buscar un modelo que mejore nuestra predicción porque el modelo actual no es demasiado bueno."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
