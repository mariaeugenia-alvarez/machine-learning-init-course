{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos y trabajo con valores perdidos\n",
    "\n",
    "En este notebook estudiaremos en mayor profundidad dos secciones del análisis exploratorio de datos: la carga y detección y gestión de datos no disponibles.\n",
    "\n",
    "Los módulos usados en este cuaderno son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profundicemos primero en la carga de datos:\n",
    "\n",
    "## Carga de datos\n",
    "\n",
    "En el notebook anterior vimos una manera sencilla de leer archivos csv pero los archivos csv no siempre vendrán limpios y preparados para la lectura por eso es interesante ver algunos de los parámetros más usados del método `pd.read_csv()` así como la posibilidad de leer dataframes de otros tipos de archivos como archivos .txt u hojas de Excel.\n",
    "\n",
    "A la hora de leer un csv es interesante abrir el archivo con un editor de textos para comprobar cómo se presenta información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro delimiter separa los elementos según el delimitador indicado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cine = pd.read_csv('./data/cine.csv', delimiter='::')\n",
    "data_cine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro header indica si existe o no cabecero para la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cine = pd.read_csv('./data/cine.csv', delimiter='::', header = None)\n",
    "data_cine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro names nos permite dar nombre a nuestras columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cine = pd.read_csv('./data/cine.csv', delimiter='::', header = None, names=['Index', 'Film', 'Genre'])\n",
    "data_cine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro index_col nos permite indicar que una de las columnas del csv debe usarse como índice del dataframe. Esta columna no puede tener valores repetidos pues el índice asigna un valor único a cada fila:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cine = pd.read_csv('./data/cine.csv', delimiter='::', header = None, names=['Index', 'Film', 'Genre'], index_col=['Index'], engine='python')\n",
    "data_cine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra situación muy habitual es que algunas de las primeras líneas del archivo vengan ocupadas por información relevante (no debe ser borrada) pero que no forma parte de nuestra tabla. En estos casos es útil el parámetro skiprows que indica el número de líneas al principio del csv a ignorar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_peli = pd.read_csv('./data/peliculas.csv', skiprows=6)\n",
    "data_peli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivos .txt\n",
    "\n",
    "A la hora de leer arrays de archivos .txt usamos el método de numpy `np.loadtxt()`. Comprobamos el archivo y observamos que se emplea la coma como separador de datos. Esto será util cuando queramos cargar vectores o archivos con una sola columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips =  np.loadtxt('./data/tips.txt', delimiter=',') \n",
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hojas de excel\n",
    "\n",
    "Pandas también nos permite mediante el método `read_excel` leer tablas almacenadas en hojas de Excel. Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empleamos el parámetro sheet_name para indicar la hoja que deseamos que lea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexcel = pd.read_excel('./data/clientes.xlsx', sheet_name = \"Hoja2\") \n",
    "dfexcel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son las principales fuentes de datos y los parámetros más relevantes del método de pandas `read_csv()`. Existen otros muchos parámetros menos utilizados pero que en caso de que necesites puedes consultar en la [documentación de la función](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "\n",
    "***\n",
    "\n",
    "## Trabajo con valores perdidos\n",
    "\n",
    "Como se comentó en el notebook anterior no siempre se dispone de toda la información y en nuestro dataframe pueden aparecer casillas vacías con las que debemos trabajar. Existen cuatro técnicas a la hora de enfrentar esta situación:\n",
    "\n",
    "* __Trabajar con los valores perdidos.__\n",
    "* __Eliminar registros__\n",
    "* __Eliminar variables__\n",
    "* __Imputar valores__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación analizaremos las cuatro opciones, comenzamos cargando unos datos con bastantes huecos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data = pd.read_csv('./data/nan_data.csv')\n",
    "nan_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el tamaño del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cómo se distribuyen los valores perdidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajar con valores perdidos\n",
    "\n",
    "Multitud de algoritmos y modelos están diseñados para funcionar con datos vacíos o NaN's. Se puede trabajar con ellos sin pérdida de precisión y sin más dificultades. Es una opción perfectamente válida y que nos ahorra tiempo en el preprocesamiento.\n",
    "\n",
    "### Eliminar registros\n",
    "\n",
    "En ocasiones los NA's se concentran en algunos registros, en este caso puede ser útil eliminar las filas con NA's para lo que empleamos el método `dropna()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_registers = nan_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_registers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_registers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso nos quedaríamos sin filas por lo que no parece una buena idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar variables\n",
    "\n",
    "Mediante el mismo método podemos probar a eliminar columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_variables = nan_data.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_variables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso nos quedaríamos con una única columna. Tampoco parece muy buena idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputar valores\n",
    "\n",
    "En ocasiones si supone una gran pérdida de información se procede a la imputación de valores. Existen distintas técnicas pero la más utilizada con diferencia es el empleo de la mediana. El método es sencillo:\n",
    "\n",
    "* Seleccionamos la variable en la que queremos sustituir los valores vacíos por valores estimados.\n",
    "* Calculamos la mediana de los valores disponibles.\n",
    "* \"Rellenamos\" todos los valores perdidos con la mediana\n",
    "\n",
    "Para ello podemos emplear el método `fillna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data.Variable_E.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la Variable_E tenemos 3167 observaciones perdidas. Por lo que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data.shape[0] - 3167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disponemos de 78 observaciones. Calculamos la mediana de dichas observaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_e = nan_data.Variable_E.median()\n",
    "median_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente mediante el método `fillna()` reemplazamos los valores perdidos por ese valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_E = nan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_E['Variable_E'] =nan_data.Variable_E.fillna(median_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_E.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la Variable_E no tiene ningún valor perdido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_E.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el problema que enfoquemos y la densidad de valores perdidos de nuestra tabla nos decantaremos por una u otra opción, no existen reglas para decidirlo a priori."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
