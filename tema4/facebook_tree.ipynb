{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de Regresión\n",
    "\n",
    "En este notebook vamos a retomar los datos de Facebook con los que trabajamos en la tercera sección y vamos a construir sobre ellos árboles de regresión para predecir de nuevo el número de likes de una publicación dadas algunas características como el tipo de publicación o la hora de publicación. En este modelo haremos especial hincapié en la explicabilidad interpretando los árboles generados. \n",
    "\n",
    "Para el desarrollo de este notebook emplearemos los siguientes módulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Como siempre comenzamos cargando los datos. Cargamos los datos de Facebook ya limpios y procesados. Si no recuerdas cómo se realizó este preprocesamiento puedes revisar el notebook de la regresión lineal del tema 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fb = pd.read_csv('./data/cleaned_facebook.csv')\n",
    "data_fb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_fb.drop('like', axis=1)\n",
    "y = data_fb['like']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos como siempre nuestros datos en datos de entrenamiento y datos de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del modelo\n",
    "\n",
    "Una vez dispuestos los datos comenzamos con la construcción del modelo. Usaremos de nuevo el módulo scikit-learn. Comenzamos instanciando el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_one = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez instanciado el modelo con las especificaciones que vienen por defecto ajustamos el modelo empleando los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one = tree_one.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas dos líneas de código hemos construido nuestro primer árbol de regresión. Podemos observar su profundidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O el número mínimo de observaciones para producir una separación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one.min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que una de las partes más importantes de los árboles es que podemos visualizar la estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(tree_one,\n",
    "               feature_names = X_train.columns, \n",
    "               filled = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el árbol generado es terriblemente complejo. Es muy probable que se esté produciendo overfitting, vamos a comprobarlo empleando el estadístico R2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = tree_one.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = tree_one.predict(X_test)\n",
    "r2_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente nos encontramos ante un caso de overfitting enorme. El modelo es casi perfecto en entrenamiento (recordemos que la perfección en R2 se estima como 1) y muy muy malo en validación con un R2 negativo. \n",
    "\n",
    "Esto no sorprende, sabemos que los árboles tienden a sobreajustarse cuando se complican demasiado. Generamos a continuación un árbol en el que controlaremos la complejidad.\n",
    "\n",
    "Instanciamos un nuevo modelo en el que fijamos una profundidad máxima de 2 y un número mínimo de muestras para separación de 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_tree = tree.DecisionTreeRegressor(max_depth=2, min_samples_split=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos este nuevo modelo a los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_tree = tuned_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo evaluamos su calidad y comprobamos el overfitting mediante el estadístico R2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tuned_train = tuned_tree.predict(X_train)\n",
    "r2_score(y_train, y_pred_tuned_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tuned_test = tuned_tree.predict(X_test)\n",
    "r2_score(y_test, y_pred_tuned_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo es aun mejorable. Te animo a probar nuevas configuraciones que puedan mejorarlo. Una vez elegido nuestro modelo podemos calcular el error medio cuadrático para poder compararlo con otros modelos como el de regresión lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train = mean_squared_error(y_train, y_pred_tuned_train)\n",
    "np.sqrt(mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = mean_squared_error(y_test, y_pred_tuned_test)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos unos resultados catastróficos. Esto tiene sentido, recordemos que la regresión lineal nos devolvía ya unos resultados bastante malos y en los árboles estamos sacrificando precisión a cambio de explicabilidad por lo que estos resultados no sorprenden tanto. Pero veamos la gran ventaja. Ahora podemos representar gráficamente los árboles y clasificar cualquier nuevo elemento mediante solo 2 comprobaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "# DOT data\n",
    "dot_data = tree.export_graphviz(tuned_tree, out_file=None, \n",
    "                                feature_names=X_train.columns,  \n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así para cualquier nueva observación bastara comprobar si es de categoría 1 y en caso de serlo si fue publicada en septiembre o no. En caso de no serlo si fue publicada de miércoles o no. Con solo estas dos preguntas podemos generar nuestra predicción. Esto además nos permite tomar decisiones, por ejemplo si tenemos un post de categoría uno y estamos pensando en publicarlo en septiembre quizá sea mejor esperar a octubre donde la predicción es de 170 likes más. Este es el mayor interés de los árboles, no tanto su precisión si no la conclusiones que se pueden sacar a partir de sus bifurcaciones así como la sencillez para nuevas inferencias que puede ser de una enorme utilidad si pensamos por ejemplo en decisiones en salas de espera de hospitales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
