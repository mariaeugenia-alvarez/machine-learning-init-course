{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión para el Titanic\n",
    "\n",
    "En este notebook vamos a construir árboles de clasificación para predecir la supervivencia de los pasajeros del Titanic. Una vez construidos los árboles compararemos los resultados con los de la regresión logística construida anteriormente. En este notebook usaremos los siguientes módulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos cargando los datos de entrenamiento y validación que genereamos en el notebook de la Regresión Logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/xtrain_tit.csv')\n",
    "X_test = pd.read_csv('./data/xtest_tit.csv')\n",
    "y_train = pd.read_csv('./data/ytrain_tit.csv')\n",
    "y_test = pd.read_csv('./data/ytest_tit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los datos se han cargado de manera correcta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del modelo\n",
    "\n",
    "Comenzamos construyendo un árbol básico. Empleamos la librería sklearn que ya habíamos utilizado previamente para las dos regresiones. Comenzamos como siempre instanciando el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_one = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez instancia el modelo, podemos ajustarlo a nuestros datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one = tree_one.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos algunos parámetros como la profundidad o el número mínimo de muestras para que se continuen generando divisiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one.min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos representar el árbol de manera visual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(tree_one,\n",
    "               feature_names = X_train.columns, \n",
    "               filled = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos apreciar este árbol es terriblemente complejo con miles de ramas perdiendo prácticamente toda su explicabilidad. Evaluemos ahora el modelo, para ello comenzamos generando nuestras predicciones en el conjunto de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_one = tree_one.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos en primer lugar la tasa de acierto en entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que estamos incurriendo en algo de overfitting. Hay prácticamente un 15% de diferencia entre entrenamiento y validación. Este es el primer indicador de que el modelo se puede mejorar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya vimos previamente este dataset está desbalanceado por lo que es necesario calcular otras métricas para poder evaluar de manera correcta la calidad del modelo. Comencemos construyendo la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_one)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de esa matriz podemos calcular las métricas específicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último construimos la curva ROC y calculamos el área bajo la curva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, tree_one.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, tree_one.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Primer árbol (Área bajo la curva = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ratio de falsos positivos')\n",
    "plt.ylabel('Ratio de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_ROC') si descomentas esta línea puedes guardar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol visto hasta ahora es mejorable en dos sentidos:\n",
    "\n",
    "* Es un árbol muy complejo con multitud de nodos lo que dificulta enormemente su explicabilidad.\n",
    "* Sufre de sobreajuste, hay una gran diferencia en la tasa de acierto en entre entrenamiento y validación.\n",
    "\n",
    "Podemos construir un nuevo árbol en el que reduzcamos los nodos, lo cual mejora estas dos situaciones, los vuelve más explicables y reduce el sobreajuste. Para ello manipulamos dos parámetros: la máxima profundidad, en la que decidimos cuál será la máxima altura que le permitimos crecer al árbol y el número mínimo de muestras para continuar dividiendo los nodos. Para reducir el overfitting fijamos la máxima profundidad en 4 (frente a la altura 17 que tenía el árbol  anterior) y el número mínimo de muestras a 5 frente a las 2 del árbol inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 3\n",
    "min_samples_split = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez fijados los nuevos valores de los parámetros, instanciamos un nuevo árbol y ajustamos el modelo de nuevo a los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tree = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "reduced_tree = reduced_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo recurrimos al conjunto de validación para evaluar la calidad del modelo, para ello comenzamos generando las predicciones en el conjunto de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reduced = reduced_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez construidas las predicciones podemos comenzar intentando evaluar el overfitting mediante la tasa de acierto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta decisión hemos conseguido atajar el sobreajuste y observamos de hecho que la métrica para validación es ligeramente superior a la de entrenamiento. Y es un 7% superior a la del árbol anterior. Examinemos de nuevo la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_reduced)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hemos reducido un falso negativo y 8 falsos positivos mejorando sobre todo el número de verdaderos negativos predicho, es decir, reducimos la gente que se clasificaba como superviviente erróneamente.\n",
    "\n",
    "Observemos las métricas que se pueden extraer de la matriz de confusión para este nuevo árbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la precisión ha mejorado enormemente y el recall mejora para la clase 1 (y se conserva para la 2). El f1 mejora también notablemente. Construimos finalmente la curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, reduced_tree.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, reduced_tree.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Árbol restringido (Área bajo la curva = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ratio de falsos positivos')\n",
    "plt.ylabel('Ratio de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_ROC') si descomentas esta línea puedes guardar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal y como era de esperar esta métrica mejora respecto al árbol anterior reflejando la mejora del clasificador que ya intuíamos cuando examinamos las demás métricas.\n",
    "\n",
    "## Interpretación gráfica y explicabilidad\n",
    "\n",
    "Por último recordemos que el árbol anterior era muy complejo de graficar y explicar. Veamos este árbol en el que hemos limitado la profundidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "# DOT data\n",
    "dot_data = tree.export_graphviz(reduced_tree, out_file=None, \n",
    "                                feature_names=X_train.columns,  \n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este árbol podemos clasificar a todos los pasajeros mediante solo tres preguntas con una precisión del 83%. Un resultado de muy buena calidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
