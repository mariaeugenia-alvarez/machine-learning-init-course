{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging para la regresión\n",
    "\n",
    "En este notebook vamos a emplear técnicas de bagging para predecir el número de likes de una publicación. Empleamos de nuevo los datos ya limpios extraídos en los notebook de la tercera sección.\n",
    "\n",
    "Los módulos a emplear son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos a partir del csv generado en la tercera sección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fb = pd.read_csv('./data/cleaned_facebook.csv')\n",
    "data_fb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos la variable objetivo (like) del resto de variables que actuarán como predictoras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_fb.drop('like', axis=1)\n",
    "y = data_fb['like']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en datos de entrenamiento y datos de validación con el fin de detectar el overfitting y generar una medida objetiva de la calidad del modelo que nos permita compararlo con los ya calculados hasta ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del modelo\n",
    "\n",
    "A continuación procedemos a generar nuestro modelo de bagging. Si recordamos los modelos de bagging se construyen como una unión de árboles por lo que instanciamos en primer lugar el tipo de árbol básico; un árbol de regresión como el que vimos en notebook previos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "base_reg = DecisionTreeRegressor() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos como siempre instanciando el modelo al que le pasamos como parámetro el tipo de modelo base que vamos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "regressorBag = BaggingRegressor(base_estimator = base_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez instanciado el modelo procedemos como ya es habitual a ajustarlo a los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressorBag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar el número de estimadores (de árboles) empleados así como las máximas muestras permitidas en un nodo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressorBag.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressorBag.max_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho esto ya tenemos nuestro modelo entrenado, podemos proceder como siempre al cálculo del R2 en los datos de entrenamiento y validación para medir la calidad y detectar el sobreajuste de haberlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bag_pred_train = regressorBag.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train, y_bag_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bag_pred_test = regressorBag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_bag_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detectamos un overfitting bastante alto. Vamos a jugar con algunos parámetros para intentar mejorar nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 1000\n",
    "max_samples = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressorBag_tuned = BaggingRegressor(base_estimator = base_reg, n_estimators = num_trees, \n",
    "                                      max_samples= max_samples, random_state=21)\n",
    "regressorBag_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bag_tuned_pred_train = regressorBag_tuned.predict(X_train)\n",
    "r2_score(y_train, y_bag_tuned_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bag_tuned_pred_test = regressorBag_tuned.predict(X_test)\n",
    "r2_score(y_test, y_bag_tuned_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mitigado el problema del overfitting procedemos al cálculo del error medio cuadrático del bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_test = mean_squared_error(y_test, y_bag_tuned_pred_test)\n",
    "np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último el bagging nos permite observar que variables han sido las más importantes a la hora de construir nuestras predicciones, las observamos agrupadas en un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = np.mean([\n",
    "    tree.feature_importances_ for tree in regressorBag_tuned.estimators_\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "feature_importance_dic = {}\n",
    "for element in feature_importances:\n",
    "    feature_importance_dic[X_train.columns[i]] = element\n",
    "    i = i + 1\n",
    "importance_df = pd.DataFrame.from_dict(feature_importance_dic, orient='index', columns=['Importancia'])\n",
    "importance_df.sort_values('Importancia', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el número total de likes es sin duda la variable más indicativa para este modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
