{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística para el Titanic\n",
    "\n",
    "En este notebook buscamos construir un modelo de regresión logística para predecir la variable survival que nos indica si el pasajero ha sobrevivido (1) al naufragio del Titanic o ha fallecido (0).\n",
    "\n",
    "En este notebook usaremos los siguientes módulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos cargando los datos y preprocesando las variables.\n",
    "\n",
    "## Preprocesamiento\n",
    "\n",
    "### Valores perdidos\n",
    "\n",
    "Empezamos observando el número de valores perdidos para cada variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('./data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso completaremos las variables perdidas edad y puerto de embarcamiento pues pueden resultar interesantes.  Para la variable edad empleamos la mediana para sustituir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Age'].median() # calculamos la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(titanic_data['Age'].median(), inplace=True) # rellenamos los valores perdidos con la mediana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable del puerto de embarque la completamos con el valor más habitual, es decir, con la moda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Embarked'].mode()[0] # calculamos la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos estudiar la variable cabina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Cabin'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la variable cabina no parece contener mucha información relevante. Toma 147 valores distintos para menos de 900 variables por lo que la descartaremos.\n",
    "\n",
    "### Descarte de variables\n",
    "\n",
    "Como mencioamos antes podemos prescindir de la variable cabina. Además las variables PassengerId, Name, Ticket y Fare tampoco parecen aportar mucha información por lo que nos quedamos con las variables restantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = titanic_data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las variables dummies que usaremos para codificar las tres variables categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data= pd.get_dummies(cleaned_data, columns=['Pclass', 'Sex', 'Embarked' ], drop_first= True)  #automatiza la generación de dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este será el dataset con el que trabajaremos. Procedemos a continuación a dividir en datos de entrenamiento y datos de validación.\n",
    "\n",
    "## Dividiendo en datos de entrenamiento y datos de validación \n",
    "\n",
    "Con el fin de poder evaluar la calidad de nuestro modelo dividimos en datos de entrenamiento y datos de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nota.__ La semilla random_starte nos permitirá replicar esta partición en futuros notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento final\n",
    "\n",
    "Realizamos finalmente el escalado de variables que no se puede realizar hasta que se proceda a la división entre el dataset de entrenamiento y el de validación para no generar sesgo.\n",
    "\n",
    "### Escalado de variables\n",
    "\n",
    "Procedemos a continuación a escalar las variables numéricas para intentar que el método resulte algo más estable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "features= ['Age', 'SibSp', 'Parch'] #variables requieren ser escaladas\n",
    "\n",
    "X_train[features]= ss.fit_transform(X_train[features]) #transformación de entrenamiento\n",
    "X_test[features]= ss.fit_transform(X_test[features]) #transformación de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto ya tenemos nuestros datos listos para la construcción del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamo los datasets de entrenamiento y validación para poder reutilizarlos en futuros notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('./data/xtrain_tit.csv', index=False)\n",
    "X_test.to_csv('./data/xtest_tit.csv', index=False)\n",
    "y_train.to_csv('./data/ytrain_tit.csv', index=False)\n",
    "y_test.to_csv('./data/ytest_tit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del modelo\n",
    "\n",
    "Ahora que ya tenemos nuestro dataset preparado tras tratar los valores perdidos, escalarlo, generar las variables dummy etc ha llegado el momento de ajustar nuestro modelo de regresión logística. Este será el primer modelo de clasificación que ajustemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es habitual comenzamos instanciando el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras ello lo ajustamos sobre nuestros datos de entrenamiento pasándole las variables predictoras y la variable objetivo y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar los coeficientes que se han asociado a este modelo mediante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí ya tenemos un modelo capaz de realizar predicciones. A continuación predeciremos sobre el conjunto de validación para evaluar la calidad de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando la calidad del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos trabajando con dato etiquetado podemos comparar el resultado real **y_test** con el resultado predicho **y_pred** para poder evaluar la calidad del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la precisión a simple vista es bastante buena, acierta en un 83% de los casos. Como nos encontramos ante datos desbalanceados podemos proceder a calcular otras métricas para constatar si este primer buen resultado se consolida. Construímos la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los resultados son muy buenos. Nuestra regresión acierta de una manera bastante equilibrada. Podemos calcular los coeficientes observados en la parte teórica para poder posteriormente comparar de manera objetiva y sencilla otros modelos que estudiaremos en el futuro. Sklearn nos provee de un método para calcularlos y organizarlos de manera automática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último podemos calcular la curva ROC que nos será también de gran utilidad para evaluar la calidad del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test)) # el cálculo del área bajo la curva está automatizado\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1]) #la curva ROC se genera en esta línea\n",
    "plt.figure() # a partir de aquí se da formato a la gráfica\n",
    "plt.plot(fpr, tpr, label='Regresión Logística (Área bajo la curva = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ratio de falsos positivos')\n",
    "plt.ylabel('Ratio de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_ROC') si descomentas esta línea puedes guardar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el área bajo la curva aparece calculado y es de 0,83 un muy buen resultado que intentaremos mejorar en el futuro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
